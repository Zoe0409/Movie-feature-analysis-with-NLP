{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb Movies similarity from plot summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import and observe dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>release year</th>\n",
       "      <th>genre</th>\n",
       "      <th>key words</th>\n",
       "      <th>plot</th>\n",
       "      <th>run time /min</th>\n",
       "      <th>number of votes</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sharknado</td>\n",
       "      <td>2013</td>\n",
       "      <td>Action|Adventure|Comedy|Horror|Sci-Fi|Thriller</td>\n",
       "      <td>school-bus|chainsaw|psychotronic-film|hurrican...</td>\n",
       "      <td>When a freak hurricane swamps Los Angeles, nat...</td>\n",
       "      <td>86</td>\n",
       "      <td>44265</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Normal Heart</td>\n",
       "      <td>2014</td>\n",
       "      <td>Drama|History|Romance</td>\n",
       "      <td>gay|gay-men's-health-crisis|hiv|aids-epidemic|...</td>\n",
       "      <td>A gay activist attempts to raise H.I.V. and A....</td>\n",
       "      <td>132</td>\n",
       "      <td>31793</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Sunset Limited</td>\n",
       "      <td>2011</td>\n",
       "      <td>Drama</td>\n",
       "      <td>minimal-cast|dialogue-between-two-characters|s...</td>\n",
       "      <td>Through a chance encounter, two men of opposin...</td>\n",
       "      <td>91</td>\n",
       "      <td>26733</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Temple Grandin</td>\n",
       "      <td>2010</td>\n",
       "      <td>Biography|Drama</td>\n",
       "      <td>cattle|animal-husbandry|livestock|autism|feedi...</td>\n",
       "      <td>A biopic of Temple Grandin, an autistic woman ...</td>\n",
       "      <td>107</td>\n",
       "      <td>25551</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You Don't Know Jack</td>\n",
       "      <td>2010</td>\n",
       "      <td>Biography|Drama</td>\n",
       "      <td>suicide|assisted-suicide|moral-dilemma|moralit...</td>\n",
       "      <td>A look at the life and work of doctor-assisted...</td>\n",
       "      <td>134</td>\n",
       "      <td>25404</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Game Change</td>\n",
       "      <td>2012</td>\n",
       "      <td>Biography|Drama|History</td>\n",
       "      <td>american-politics|cell-phone|down-syndrome|pre...</td>\n",
       "      <td>Governor Sarah Palin of Alaska becomes Senator...</td>\n",
       "      <td>118</td>\n",
       "      <td>20092</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Princess Protection Program</td>\n",
       "      <td>2009</td>\n",
       "      <td>Comedy|Drama|Family</td>\n",
       "      <td>princess|dictator|teenager|protection|louisian...</td>\n",
       "      <td>A princess whose country has been invaded goes...</td>\n",
       "      <td>90</td>\n",
       "      <td>20083</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mean Girls 2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>sexiness|dream-girl|short-skirt|miniskirt|teen...</td>\n",
       "      <td>The Plastics are back in the long-awaited foll...</td>\n",
       "      <td>96</td>\n",
       "      <td>19579</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Wizard of Lies</td>\n",
       "      <td>2017</td>\n",
       "      <td>Biography|Crime|Drama</td>\n",
       "      <td>financial-fraud|financier|ponzi-scheme|fraudst...</td>\n",
       "      <td>The fall of Bernie Madoff, whose Ponzi scheme ...</td>\n",
       "      <td>133</td>\n",
       "      <td>19471</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sharknado 2: The Second One</td>\n",
       "      <td>2014</td>\n",
       "      <td>Action|Adventure|Comedy|Horror|Sci-Fi|Thriller</td>\n",
       "      <td>second-part|john-f.-kennedy-international-airp...</td>\n",
       "      <td>Fin and April are on their way to New York Cit...</td>\n",
       "      <td>95</td>\n",
       "      <td>17067</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  release year  \\\n",
       "0                    Sharknado          2013   \n",
       "1             The Normal Heart          2014   \n",
       "2           The Sunset Limited          2011   \n",
       "3               Temple Grandin          2010   \n",
       "4          You Don't Know Jack          2010   \n",
       "5                  Game Change          2012   \n",
       "6  Princess Protection Program          2009   \n",
       "7                 Mean Girls 2          2011   \n",
       "8           The Wizard of Lies          2017   \n",
       "9  Sharknado 2: The Second One          2014   \n",
       "\n",
       "                                            genre  \\\n",
       "0  Action|Adventure|Comedy|Horror|Sci-Fi|Thriller   \n",
       "1                           Drama|History|Romance   \n",
       "2                                           Drama   \n",
       "3                                 Biography|Drama   \n",
       "4                                 Biography|Drama   \n",
       "5                         Biography|Drama|History   \n",
       "6                             Comedy|Drama|Family   \n",
       "7                                          Comedy   \n",
       "8                           Biography|Crime|Drama   \n",
       "9  Action|Adventure|Comedy|Horror|Sci-Fi|Thriller   \n",
       "\n",
       "                                           key words  \\\n",
       "0  school-bus|chainsaw|psychotronic-film|hurrican...   \n",
       "1  gay|gay-men's-health-crisis|hiv|aids-epidemic|...   \n",
       "2  minimal-cast|dialogue-between-two-characters|s...   \n",
       "3  cattle|animal-husbandry|livestock|autism|feedi...   \n",
       "4  suicide|assisted-suicide|moral-dilemma|moralit...   \n",
       "5  american-politics|cell-phone|down-syndrome|pre...   \n",
       "6  princess|dictator|teenager|protection|louisian...   \n",
       "7  sexiness|dream-girl|short-skirt|miniskirt|teen...   \n",
       "8  financial-fraud|financier|ponzi-scheme|fraudst...   \n",
       "9  second-part|john-f.-kennedy-international-airp...   \n",
       "\n",
       "                                                plot  run time /min  \\\n",
       "0  When a freak hurricane swamps Los Angeles, nat...             86   \n",
       "1  A gay activist attempts to raise H.I.V. and A....            132   \n",
       "2  Through a chance encounter, two men of opposin...             91   \n",
       "3  A biopic of Temple Grandin, an autistic woman ...            107   \n",
       "4  A look at the life and work of doctor-assisted...            134   \n",
       "5  Governor Sarah Palin of Alaska becomes Senator...            118   \n",
       "6  A princess whose country has been invaded goes...             90   \n",
       "7  The Plastics are back in the long-awaited foll...             96   \n",
       "8  The fall of Bernie Madoff, whose Ponzi scheme ...            133   \n",
       "9  Fin and April are on their way to New York Cit...             95   \n",
       "\n",
       "   number of votes  rating  \n",
       "0            44265     3.3  \n",
       "1            31793     7.9  \n",
       "2            26733     7.4  \n",
       "3            25551     8.3  \n",
       "4            25404     7.6  \n",
       "5            20092     7.4  \n",
       "6            20083     5.6  \n",
       "7            19579     4.1  \n",
       "8            19471     6.8  \n",
       "9            17067     4.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(5)\n",
    "\n",
    "movies_df = pd.read_csv('../dataset/movie_info.csv')\n",
    "\n",
    "# show the top 10 rows\n",
    "movies_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenization and Stemming\n",
    "\n",
    "**Tokenization** is the process  by which we break down articles into individual sentences or words, as needed. Besides the tokenization method provided by NLTK, we might have to perform additional filtration to remove tokens which are entirely numeric values or punctuation.\n",
    "\n",
    "**Stemming** is the process by which we bring down a word from its different forms to the root word. This helps us establish meaning to different forms of the same words without having to deal with each form separately. \n",
    "\n",
    "First, let us perform tokenization on a small extract from Mean Girls 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Plastics',\n",
       " 'are',\n",
       " 'back',\n",
       " 'in',\n",
       " 'the',\n",
       " 'long-awaited',\n",
       " 'follow-up',\n",
       " 'to',\n",
       " 'the',\n",
       " 'smash',\n",
       " 'hit',\n",
       " 'Mean',\n",
       " 'Girls',\n",
       " 'and',\n",
       " 'now',\n",
       " 'the',\n",
       " 'clique',\n",
       " 'is',\n",
       " 'more',\n",
       " 'fashionable',\n",
       " 'funny',\n",
       " 'and',\n",
       " 'ferocious',\n",
       " 'than',\n",
       " 'ever']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize a paragraph into sentences and store in sent_tokenized\n",
    "sent_tokenized = [sent for sent in nltk.sent_tokenize(\"\"\"\n",
    "                        The Plastics are back in the long-awaited follow-up to the smash hit Mean Girls - and now the clique is more fashionable, funny, and ferocious than ever.\n",
    "                        \"\"\")]\n",
    "\n",
    "# Word Tokenize first sentence from sent_tokenized, save as words_tokenized\n",
    "words_tokenized = [word for word in nltk.word_tokenize(sent_tokenized[0])]\n",
    "\n",
    "# Remove tokens that do not contain any letters from words_tokenized\n",
    "import re\n",
    "\n",
    "filtered = [word for word in words_tokenized if re.search('[a-zA-Z]', word)]\n",
    "\n",
    "# Display filtered words to observe words after tokenization\n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different algorithms available for stemming such as the Porter Stemmer, Snowball Stemmer, and such. We shall use the Snowball Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without stemming:  ['The', 'Plastics', 'are', 'back', 'in', 'the', 'long-awaited', 'follow-up', 'to', 'the', 'smash', 'hit', 'Mean', 'Girls', 'and', 'now', 'the', 'clique', 'is', 'more', 'fashionable', 'funny', 'and', 'ferocious', 'than', 'ever']\n",
      "After stemming:    ['the', 'plastic', 'are', 'back', 'in', 'the', 'long-await', 'follow-up', 'to', 'the', 'smash', 'hit', 'mean', 'girl', 'and', 'now', 'the', 'cliqu', 'is', 'more', 'fashion', 'funni', 'and', 'feroci', 'than', 'ever']\n"
     ]
    }
   ],
   "source": [
    "# Import the SnowballStemmer to perform stemming\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# Create an English language SnowballStemmer object\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Print filtered to observe words without stemming\n",
    "print(\"Without stemming: \", filtered)\n",
    "\n",
    "# Stem the words from filtered and store in stemmed_words\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered]\n",
    "\n",
    "# Print the stemmed_words to observe words after stemming\n",
    "print(\"After stemming:   \", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now able to tokenize and stem sentences. But we may have to use the two functions repeatedly one after the other to handle a large amount of data, hence we can think of wrapping them in a function and passing the text to be tokenized and stemmed as the function argument. Then we can pass the new wrapping function, which shall perform both tokenizing and stemming instead of just tokenizing, as the tokenizer argument while creating the TF-IDF vector of the text.\n",
    "\n",
    "First, let us define a function to perform both stemming and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    \n",
    "    # Tokenize by sentence, then by word\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    \n",
    "    # Filter out raw tokens to remove noise\n",
    "    filtered_tokens = [token for token in tokens if re.search('[a-zA-Z]', token)]\n",
    "    \n",
    "    # Stem the filtered_tokens\n",
    "    stems = [stemmer.stem(word) for word in filtered_tokens]\n",
    "    \n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function on the plot of Mean Girls 2 for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'plastic', 'are', 'back', 'in', 'the', 'long-await', 'follow-up', 'to', 'the', 'smash', 'hit', 'mean', 'girl', 'and', 'now', 'the', 'cliqu', 'is', 'more', 'fashion', 'funni', 'and', 'feroci', 'than', 'ever']\n"
     ]
    }
   ],
   "source": [
    "words_stemmed = tokenize_and_stem(\"The Plastics are back in the long-awaited follow-up to the smash hit Mean Girls - and now the clique is more fashionable, funny, and ferocious than ever.\")\n",
    "print(words_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gave us the same result, which means that the function is good to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create TfidfVectorizer\n",
    "\n",
    "Computers do not understand text. These are machines only capable of understanding numbers and performing numerical computation. Hence, we must convert our textual plot summaries to numbers for the computer to be able to extract meaning from them. One simple method of doing this would be to count all the occurrences of each word in the entire vocabulary and return the counts in a vector. \n",
    "\n",
    "Term Frequency-Inverse Document Frequency (TF-IDF) is one method which overcomes the shortcomings of CountVectorizer. The Term Frequency of a word is the measure of how often it appears in a document, while the Inverse Document Frequency is the parameter which reduces the importance of a word if it frequently appears in several documents.\n",
    "\n",
    "In simplest terms, TF-IDF recognizes words which are unique and important to any given document. Let's create one for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TfidfVectorizer to create TF-IDF vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate TfidfVectorizer object with stopwords and tokenizer\n",
    "# parameters for efficient processing of text\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, max_features=200000,\n",
    "                                 min_df=2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem,\n",
    "                                 ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fit transform TfidfVectorizer\n",
    "\n",
    "Once we create a TF-IDF Vectorizer, the next step is to fit the text to it and then transform the text to produce the corresponding numeric form of the data which the computer will be able to understand and derive meaning from. To do this, we use the fit_transform() method of the TfidfVectorizer object. \n",
    "\n",
    "If we observe the TfidfVectorizer object we created, we come across a parameter stopwords. 'stopwords' are those words in a given text which do not contribute considerably towards the meaning of the sentence and are generally grammatical filler words. \n",
    "   \n",
    "On setting the stopwords to 'english', we direct the vectorizer to drop all stopwords from a pre-defined list of English language stopwords present in the nltk module. Another parameter, ngram_range, defines the length of the ngrams to be formed while vectorizing the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3167, 11538)\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform the tfidf_vectorizer with the \"plot\" of each movie\n",
    "# to create a vector representation of the plot summaries\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([x for x in movies_df[\"plot\"]])\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. K-means clustering\n",
    "\n",
    "To determine how closely one movie is related to the other by the help of unsupervised learning, we can use clustering techniques. Clustering is the method of grouping together a number of items such that they exhibit similar properties. According to the measure of similarity desired, a given sample of items can have one or more clusters. \n",
    "\n",
    "1. look for the elbow to determine the optimal number of clusters\n",
    "2. check the number of samples per group to confirm we have balanced samples accross k-means groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. look for the elbow to determine the optimal number of clusters**\n",
    "\n",
    "Mini Batch K-means algorithmâ€˜s main idea is to use small random batches of data of a fixed size, so they can be stored in memory. Each iteration of a new random sample from the dataset is obtained and used to update the clusters and this is repeated until convergence. Each mini batch updates the clusters using a convex combination of the values of the prototypes and the data, applying a learning rate that decreases with the number of iterations. This learning rate is the inverse of the number of data assigned to a cluster during the process. As the number of iterations increases, the effect of new data is reduced, so convergence can be detected when no changes in the clusters occur in several consecutive iterations.\n",
    "\n",
    "Probably the most well known method, the elbow method, in which the sum of squares at each number of clusters is calculated and graphed, and the user looks for a change of slope from steep to shallow (an elbow) to determine the optimal number of clusters. This method is inexact, but still potentially helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# init potential n_clusters\n",
    "n_clusters_list = list(range(1, 60, 1))\n",
    "# init scores\n",
    "scores = []\n",
    "# init models for cache\n",
    "kms = {}\n",
    "for n_clusters in n_clusters_list:\n",
    "    km = MiniBatchKMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        random_state=99\n",
    "    ).fit(tfidf_matrix)\n",
    "    # save models\n",
    "    kms.update({n_clusters: km})\n",
    "    # save score\n",
    "    scores.append(-1 * km.score(tfidf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x123e2a990>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for elbow to determine optimal number of clusters\n",
    "pd.DataFrame({'scores': scores}, index=n_clusters_list).plot(\n",
    "    figsize=(16, 8),\n",
    "    title='K-Means Objective Score vs. Number of Clusters',\n",
    "    grid=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "      <th>run time</th>\n",
       "      <th>votes</th>\n",
       "      <th>rating</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sharknado</td>\n",
       "      <td>When a freak hurricane swamps Los Angeles, nat...</td>\n",
       "      <td>86</td>\n",
       "      <td>44265</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Normal Heart</td>\n",
       "      <td>A gay activist attempts to raise H.I.V. and A....</td>\n",
       "      <td>132</td>\n",
       "      <td>31793</td>\n",
       "      <td>7.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Sunset Limited</td>\n",
       "      <td>Through a chance encounter, two men of opposin...</td>\n",
       "      <td>91</td>\n",
       "      <td>26733</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Temple Grandin</td>\n",
       "      <td>A biopic of Temple Grandin, an autistic woman ...</td>\n",
       "      <td>107</td>\n",
       "      <td>25551</td>\n",
       "      <td>8.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>You Don't Know Jack</td>\n",
       "      <td>A look at the life and work of doctor-assisted...</td>\n",
       "      <td>134</td>\n",
       "      <td>25404</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title                                               plot  \\\n",
       "5            Sharknado  When a freak hurricane swamps Los Angeles, nat...   \n",
       "5     The Normal Heart  A gay activist attempts to raise H.I.V. and A....   \n",
       "5   The Sunset Limited  Through a chance encounter, two men of opposin...   \n",
       "5       Temple Grandin  A biopic of Temple Grandin, an autistic woman ...   \n",
       "9  You Don't Know Jack  A look at the life and work of doctor-assisted...   \n",
       "\n",
       "   run time  votes  rating  cluster  \n",
       "5        86  44265     3.3        5  \n",
       "5       132  31793     7.9        5  \n",
       "5        91  26733     7.4        5  \n",
       "5       107  25551     8.3        5  \n",
       "9       134  25404     7.6        9  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick optimal K-means Model\n",
    "n = 12\n",
    "km = kms[n]\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "# Fit the k-means object with tfidf_matrix\n",
    "km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "# create DataFrame df_clusters for clustering analysis\n",
    "data_clusters = {\n",
    "    'title': movies_df.title.values,\n",
    "    'plot': movies_df['plot'].values,\n",
    "    'run time': movies_df['run time /min'].values,\n",
    "    'votes': movies_df['number of votes'].values,\n",
    "    'rating':movies_df.rating.values,\n",
    "    'cluster': clusters\n",
    "}\n",
    "df_clusters = pd.DataFrame(\n",
    "    data_clusters,\n",
    "    index=[clusters],\n",
    "    columns=['title','plot','run time', 'votes','rating', 'cluster']\n",
    ")\n",
    "\n",
    "df_clusters.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. check the number of samples per group to confirm we have balanced samples accross k-means groups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies included in each cluster:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster\n",
       "5      1740\n",
       "9      1176\n",
       "2        77\n",
       "6        66\n",
       "10       38\n",
       "1        18\n",
       "3        13\n",
       "11       11\n",
       "0         9\n",
       "4         7\n",
       "7         6\n",
       "8         6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of movies included in each cluster:\")\n",
    "df_clusters['cluster'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate Movie Simialrity\n",
    "\n",
    "**Use cosine similarity to calculate similarity of movie plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# get similarity matrix using tfidf matrix\n",
    "sim_matrix = cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_recommender_cosine_similarity(movie_title, K):\n",
    "    if (len(movies_df[movies_df['title']==movie_title])==0):\n",
    "        print(\"Sorry, we don't have this movie in our database. But we will take it into consideration in the future, thank you!\")\n",
    "    else:\n",
    "        movie_idx = movies_df[movies_df['title'] == movie_title].index[0]\n",
    "        return movies_df.loc[np.argsort(sim_matrix[movie_idx])[::-1][:K]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Again, let's use 'Mean Girls 2' as an example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which movie you want to search? Mean Girls 2\n",
      "How many most similarity movies you want to display? 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>release year</th>\n",
       "      <th>genre</th>\n",
       "      <th>key words</th>\n",
       "      <th>plot</th>\n",
       "      <th>run time /min</th>\n",
       "      <th>number of votes</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mean Girls 2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>sexiness|dream-girl|short-skirt|miniskirt|teen...</td>\n",
       "      <td>The Plastics are back in the long-awaited foll...</td>\n",
       "      <td>96</td>\n",
       "      <td>19579</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Certain Prey</td>\n",
       "      <td>2011</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>off-screen-rape|cell-phone-photograph|cell-pho...</td>\n",
       "      <td>Minneapolis Deputy Police Chief, Lucas Davenpo...</td>\n",
       "      <td>85</td>\n",
       "      <td>1129</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Mega Piranha</td>\n",
       "      <td>2010</td>\n",
       "      <td>Action|Adventure|Comedy|Horror|Sci-Fi|Thriller</td>\n",
       "      <td>psychotronic-film|piranha|science|amazon|tople...</td>\n",
       "      <td>A mutant strain of giant ferocious piranha esc...</td>\n",
       "      <td>92</td>\n",
       "      <td>5200</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Dinoshark</td>\n",
       "      <td>2010</td>\n",
       "      <td>Action|Adventure|Comedy|Fantasy|Horror|Sci-Fi|...</td>\n",
       "      <td>psychotronic-film|dinoshark|creature|arctic|gl...</td>\n",
       "      <td>A baby dinoshark evolves into a ferocious pred...</td>\n",
       "      <td>92</td>\n",
       "      <td>2443</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>McQueen and I</td>\n",
       "      <td>2011</td>\n",
       "      <td>Documentary|Biography</td>\n",
       "      <td>fashion-designer|fashion|catwalk|hawk|fashion-...</td>\n",
       "      <td>Profile of British fashion designer Alexander ...</td>\n",
       "      <td>71</td>\n",
       "      <td>202</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>Sexy Assassins</td>\n",
       "      <td>2012</td>\n",
       "      <td>Romance</td>\n",
       "      <td>nudity|male-nudity|female-nudity|softcore|sex</td>\n",
       "      <td>A gorgeous hit woman pulls the trigger on pass...</td>\n",
       "      <td>79</td>\n",
       "      <td>81</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Donald Trump's The Art of the Deal: The Movie</td>\n",
       "      <td>2016</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>nazi-salute|donald-trump-character|looking-at-...</td>\n",
       "      <td>Funny or Die presents a satirical rendition of...</td>\n",
       "      <td>50</td>\n",
       "      <td>3583</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Beyond Sherwood Forest</td>\n",
       "      <td>2009</td>\n",
       "      <td>Action|Adventure|Fantasy</td>\n",
       "      <td>sword-and-sorcery|stealing-from-the-rich-givin...</td>\n",
       "      <td>England 1174: King Richard is away fighting th...</td>\n",
       "      <td>93</td>\n",
       "      <td>1253</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Teen Spirit</td>\n",
       "      <td>2011</td>\n",
       "      <td>Comedy|Drama|Fantasy</td>\n",
       "      <td>prom|ghost-girl|female-ghost|female-protagonis...</td>\n",
       "      <td>The story is about Amber, a mean popular girl ...</td>\n",
       "      <td>82</td>\n",
       "      <td>6691</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>Glamour Models, Mum and Me</td>\n",
       "      <td>2010</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>glamour-models|female-nudity|nudity|plastic-su...</td>\n",
       "      <td>The story of an extraordinary mother-daughter ...</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              title  release year  \\\n",
       "7                                      Mean Girls 2          2011   \n",
       "489                                    Certain Prey          2011   \n",
       "73                                     Mega Piranha          2010   \n",
       "183                                       Dinoshark          2010   \n",
       "1402                                  McQueen and I          2011   \n",
       "1868                                 Sexy Assassins          2012   \n",
       "117   Donald Trump's The Art of the Deal: The Movie          2016   \n",
       "439                          Beyond Sherwood Forest          2009   \n",
       "54                                      Teen Spirit          2011   \n",
       "2734                     Glamour Models, Mum and Me          2010   \n",
       "\n",
       "                                                  genre  \\\n",
       "7                                                Comedy   \n",
       "489                               Action|Crime|Thriller   \n",
       "73       Action|Adventure|Comedy|Horror|Sci-Fi|Thriller   \n",
       "183   Action|Adventure|Comedy|Fantasy|Horror|Sci-Fi|...   \n",
       "1402                              Documentary|Biography   \n",
       "1868                                            Romance   \n",
       "117                                              Comedy   \n",
       "439                            Action|Adventure|Fantasy   \n",
       "54                                 Comedy|Drama|Fantasy   \n",
       "2734                                        Documentary   \n",
       "\n",
       "                                              key words  \\\n",
       "7     sexiness|dream-girl|short-skirt|miniskirt|teen...   \n",
       "489   off-screen-rape|cell-phone-photograph|cell-pho...   \n",
       "73    psychotronic-film|piranha|science|amazon|tople...   \n",
       "183   psychotronic-film|dinoshark|creature|arctic|gl...   \n",
       "1402  fashion-designer|fashion|catwalk|hawk|fashion-...   \n",
       "1868      nudity|male-nudity|female-nudity|softcore|sex   \n",
       "117   nazi-salute|donald-trump-character|looking-at-...   \n",
       "439   sword-and-sorcery|stealing-from-the-rich-givin...   \n",
       "54    prom|ghost-girl|female-ghost|female-protagonis...   \n",
       "2734  glamour-models|female-nudity|nudity|plastic-su...   \n",
       "\n",
       "                                                   plot  run time /min  \\\n",
       "7     The Plastics are back in the long-awaited foll...             96   \n",
       "489   Minneapolis Deputy Police Chief, Lucas Davenpo...             85   \n",
       "73    A mutant strain of giant ferocious piranha esc...             92   \n",
       "183   A baby dinoshark evolves into a ferocious pred...             92   \n",
       "1402  Profile of British fashion designer Alexander ...             71   \n",
       "1868  A gorgeous hit woman pulls the trigger on pass...             79   \n",
       "117   Funny or Die presents a satirical rendition of...             50   \n",
       "439   England 1174: King Richard is away fighting th...             93   \n",
       "54    The story is about Amber, a mean popular girl ...             82   \n",
       "2734  The story of an extraordinary mother-daughter ...             60   \n",
       "\n",
       "      number of votes  rating  \n",
       "7               19579     4.1  \n",
       "489              1129     5.4  \n",
       "73               5200     2.4  \n",
       "183              2443     3.1  \n",
       "1402              202     7.4  \n",
       "1868               81     6.2  \n",
       "117              3583     5.9  \n",
       "439              1253     4.5  \n",
       "54               6691     5.5  \n",
       "2734               21     6.6  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title = str(input(\"which movie you want to search? \"))\n",
    "K = int(input(\"How many most similarity movies you want to display? \"))\n",
    "\n",
    "movie_recommender_cosine_similarity(movie_title, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What if we input some movie that doesn't exist in the dataset? say input \"I am not a movie\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which movie you want to search? I am not a movie\n",
      "How many most similarity movies you want to display? 10\n",
      "Sorry, we don't have this movie in our database. But we will take it into consideration in the future, thank you!\n"
     ]
    }
   ],
   "source": [
    "movie_title = str(input(\"which movie you want to search? \"))\n",
    "K = int(input(\"How many most similarity movies you want to display? \"))\n",
    "\n",
    "movie_recommender_cosine_similarity(movie_title, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
